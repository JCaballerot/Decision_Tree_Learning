{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWwHr4mB/hv8308G344AHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCaballerot/Decision_Tree_Learning/blob/main/1.%20Classification_trees/%C3%81rboles_de_Clasificaci%C3%B3n_en_Python_con_Databricks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.ctic.uni.edu.pe/wp-content/uploads/2022/04/588px-x-348px-web-1.png\" alt=\"HTML5 Icon\" width=\"900\" height=\"350\" >"
      ],
      "metadata": {
        "id": "D4q1GHX8ACmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1 align=center><font size = 5>Laboratorio: Árboles de Clasificación en Python con Databricks\n",
        "</font></h1>\n"
      ],
      "metadata": {
        "id": "HlYWJtrTAF3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivos\n",
        "- Aplicar técnicas de preprocesamiento de datos categóricos utilizando Target Encoding.\n",
        "- Balancear un conjunto de datos desbalanceado utilizando class_weight.\n",
        "- Manejar los valores faltantes de forma adecuada y aplicar el tratamiento correspondiente en los conjuntos de entrenamiento y prueba.\n",
        "- Construir, explorar y visualizar un árbol de clasificación.\n",
        "- Optimizar hiperparámetros del árbol utilizando Grid Search.\n",
        "- Calcular y explicar las métricas principales: Accuracy y Gini."
      ],
      "metadata": {
        "id": "QJPz0Yg8AP4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "WVyamweOBGFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tabla de Contenidos\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "    \n",
        "1. <a href=\"#item31\">Introducción</a>  \n",
        "\n",
        "2. <a href=\"#item32\">Preprocesamiento de Datos</a>  \n",
        "    - Carga y revisión de los datos\n",
        "    - Muestreo de datos\n",
        "    - Tratamiento de valores faltantes\n",
        "    - Encoding de datos categóricos (Target Encoding)\n",
        "\n",
        "3. <a href=\"#item33\">Balanceo de datos</a>  \n",
        "    - Reflexión sobre el desbalanceo y uso de class_weight\n",
        "\n",
        "4. <a href=\"#item33\">Construcción y Visualización del Árbol de Clasificación</a>  \n",
        "    - Creación y visualización gráfica del árbol\n",
        "\n",
        "5. <a href=\"#item34\">Optimización del Modelo</a>  \n",
        "    - Predicciones y evaluación del modelo\n",
        "    - Uso de Grid Search para optimizar hiperparámetros\n",
        "\n",
        "6. <a href=\"#item34\">Evaluación del modelo</a>  \n",
        "    - Cálculo y explicación de Accuracy y Gini\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YNi3KKY8AZIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introducción\n"
      ],
      "metadata": {
        "id": "NjC8ov9kBJPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este laboratorio, aprenderemos a construir un árbol de clasificación utilizando técnicas avanzadas de preprocesamiento y optimización. La base de datos utilizada será HM_FLUJOS_fad_mvp2.csv. El objetivo será predecir la variable DEF12 (indicador de incumplimiento) basándonos en una serie de variables numéricas y categóricas."
      ],
      "metadata": {
        "id": "ZvOGVhKoBLXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocesamiento de Datos\n"
      ],
      "metadata": {
        "id": "8st-xBIGBNri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carga del Dataset**\n",
        "\n",
        "Primero, cargamos el dataset y revisamos su estructura.\n",
        "\n"
      ],
      "metadata": {
        "id": "mMbgivOFBQIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el dataset\n",
        "pddf = pd.read_csv('/Workspace/Users/jcaballerot@bcp.com.pe/2024Q3 - Decision Trees/data/HM_FLUJOS_fad_mvp2.csv', index_col=0)\n",
        "\n",
        "# Mostrar las primeras filas del dataset\n",
        "pddf.head()\n"
      ],
      "metadata": {
        "id": "kf7VSbObBRLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Muestreo de Datos**\n",
        "\n",
        "Dividimos los datos en conjuntos de entrenamiento y prueba, donde DEF12 será la variable objetivo y las variables numéricas y categóricas se utilizarán como características."
      ],
      "metadata": {
        "id": "kOkvYL9nBXCI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRBeBbk3_p5T"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definir las variables numéricas y categóricas\n",
        "features = [\n",
        " 'MONTO', 'MTO_DEURCCVIG', 'MTO_DEURCCVIG_AVGU12', 'R_MTODEURCCVIG_AVGU06_AVGU12', 'MTO_ABODEP',\n",
        " 'MTO_ABODEP_AVGU12', 'FRQ_PASPM_GT1000U06', 'FRQ_PASPM_GT1000U12', 'MTO_PAS_AVGU03', 'MTO_PAS_AVGU06',\n",
        " 'MTO_PAS_AVGU12', 'R_PASPM_U03U06', 'R_PASPM_U06U12', 'MTO_PASFM', 'MTO_PASFM_AVGU12',\n",
        " 'R_MTOAPROB_VTAEST', 'R_MTOAPROB_PASAVGU12', 'R_MTOAPROB_ABODEPAVGU12', 'R_MTODEUAVGU12_VTAEST',\n",
        " 'R_MTODEUAVGU12_PASAU12', 'R_MTODEUAVGU12_ABODEPAU12', 'MAX_CTDDIAATRASO', 'MAX_CTDDIAATRASO_U06',\n",
        " 'MAX_CTDDIAATRASO_NOBCP'\n",
        "]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['CAT_SUNAT_SUNATRES']\n",
        "\n",
        "# Definir las características (X) y la variable objetivo (y)\n",
        "X = pddf[features + categorical_columns]\n",
        "y = pddf['DEF12']\n"
      ],
      "metadata": {
        "id": "BS1_iZLDBem5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=123)"
      ],
      "metadata": {
        "id": "voQYoUOoBftQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tratamiento de Valores Faltantes**\n",
        "\n",
        "Los valores faltantes pueden afectar el rendimiento del modelo, por lo que debemos imputarlos de forma adecuada. Usaremos la media para las variables numéricas y aplicaremos el mismo tratamiento en el conjunto de prueba."
      ],
      "metadata": {
        "id": "4SwHj-KhBhpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rellenar valores faltantes con la media en las variables numéricas\n",
        "X_train[features] = X_train[features].fillna(X_train[features].mean())\n",
        "X_test[features] = X_test[features].fillna(X_train[features].mean())\n"
      ],
      "metadata": {
        "id": "aOOY47DBBk9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Encoding para Variables Categóricas**\n",
        "\n",
        "Aplicamos Target Encoding a la variable categórica CAT_SUNAT_SUNATRES utilizando la relación con la variable objetivo DEF12."
      ],
      "metadata": {
        "id": "m8nZAvJaBnYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# Aplicar Target Encoding\n",
        "encoder = TargetEncoder(cols=categorical_columns)\n",
        "X_train = encoder.fit_transform(X_train, y_train)\n",
        "X_test = encoder.transform(X_test)"
      ],
      "metadata": {
        "id": "jVGNuKXhBraj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Balanceo de Datos\n"
      ],
      "metadata": {
        "id": "PL24vQZ9BtVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Al observar el dataset, podemos encontrar un desbalance en las clases de DEF12. Esto significa que, sin el tratamiento adecuado, el modelo podría inclinarse hacia la predicción de la clase mayoritaria. Para mitigar este problema, utilizaremos la técnica de class_weight='balanced' en el modelo de clasificación, que ajusta los pesos de las clases de acuerdo a su frecuencia en el dataset.\n"
      ],
      "metadata": {
        "id": "frlkKRjMBww-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar el desbalanceo en el conjunto de entrenamiento\n",
        "print(y_train.value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "tkfdCx43B0Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\", color_codes = True)\n",
        "sns.set(rc={'figure.figsize':(8,4)})\n",
        "\n",
        "sns.countplot(x = 'DEF12', data = pddf, palette = 'hls')\n"
      ],
      "metadata": {
        "id": "y-OF07x-B_-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Construcción y Visualización del Árbol de Clasificación\n",
        "\n"
      ],
      "metadata": {
        "id": "OPFflzpxB3I6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora entrenamos el árbol de clasificación, aplicando class_weight para balancear las clases y utilizamos la visualización del árbol."
      ],
      "metadata": {
        "id": "-YeD-w4DB6Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Definir el modelo con class_weight balanceado\n",
        "clf = DecisionTreeClassifier(max_depth=5,\n",
        "                             class_weight='balanced',\n",
        "                             random_state=123)\n",
        "\n",
        "# Entrenar el modelo\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "-PEuGEd1CQph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ajustar el tamaño de la figura\n",
        "plt.figure(figsize=(60, 20))\n",
        "\n",
        "# Graficar el árbol de decisión\n",
        "tree.plot_tree(clf,\n",
        "               feature_names=features,\n",
        "               filled=True,\n",
        "               fontsize=20,  # Ajustar el tamaño de la fuente aquí\n",
        "               node_ids=True)  # Opcional: añadir IDs a los nodos para referencia\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FhZ_AWv4CW9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Optimización del Modelo (Grid Search)\n"
      ],
      "metadata": {
        "id": "3EG5noN4Bwqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos un Grid Search para optimizar los hiperparámetros del modelo, buscando la mejor combinación de profundidad del árbol y número mínimo de muestras por hoja."
      ],
      "metadata": {
        "id": "CGFlaGc2Cq8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir los hiperparámetros a buscar\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_leaf': [0.01, 0.05, 0.1],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Realizar el Grid Search con validación cruzada\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1, return_train_score=True)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Ver los mejores parámetros\n",
        "print(\"Mejores parámetros encontrados: \", grid_search.best_params_)\n"
      ],
      "metadata": {
        "id": "Goa32urNCsjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener resultados en forma de DataFrame\n",
        "results = pd.DataFrame(grid_search.cv_results_)"
      ],
      "metadata": {
        "id": "Vtuy_mzzDy5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Obtener los resultados del Grid Search\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# Calcular el Gini (2 * AUC - 1) para train y test\n",
        "results['gini_train'] = 2 * results['mean_train_score'] - 1\n",
        "results['gini_test'] = 2 * results['mean_test_score'] - 1\n",
        "\n",
        "# Seleccionar las columnas de interés\n",
        "results_df = results[['param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split',\n",
        "                      'param_criterion', 'gini_train', 'gini_test']]\n",
        "\n",
        "# Mostrar la tabla de resultados\n",
        "results_df.head()\n"
      ],
      "metadata": {
        "id": "AUFBXhR2EDH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Gráfico de Gini vs max_depth\n",
        "plt.figure(figsize=(10, 6))\n",
        "for criterion in results_df['param_criterion'].unique():\n",
        "    # Filtrar por criterio\n",
        "    subset = results_df[results_df['param_criterion'] == criterion]\n",
        "\n",
        "    plt.plot(subset['param_max_depth'], subset['gini_train'], label=f'Train {criterion}', marker='o')\n",
        "    plt.plot(subset['param_max_depth'], subset['gini_test'], label=f'Test {criterion}', marker='x')\n",
        "\n",
        "# Etiquetas y título\n",
        "plt.xlabel('max_depth')\n",
        "plt.ylabel('Gini')\n",
        "plt.title('Gini vs max_depth para Train y Test')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uPtllWSwEFam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Evaluación del Modelo\n"
      ],
      "metadata": {
        "id": "Nu8zsmyKBwj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**\n",
        "\n",
        "La métrica Accuracy mide la proporción de predicciones correctas."
      ],
      "metadata": {
        "id": "7U2NktqPC1Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predicciones en el conjunto de prueba\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calcular la Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "PZ3nDtFvC3WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gini**\n",
        "\n",
        "El índice de Gini se calcula como 2 * AUC - 1, y mide la capacidad del modelo para diferenciar entre clases."
      ],
      "metadata": {
        "id": "-8MEfbtSC5DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Calcular AUC\n",
        "auc = roc_auc_score(y_test, grid_search.predict_proba(X_test)[:,1])\n",
        "\n",
        "# Calcular Gini\n",
        "gini = 2 * auc - 1\n",
        "print(\"Gini:\", gini)\n"
      ],
      "metadata": {
        "id": "4FB6MoGTC9jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "\n",
        "En este laboratorio, hemos cubierto los pasos necesarios para construir un árbol de clasificación, desde el preprocesamiento con Target Encoding y el manejo de valores faltantes, hasta la optimización del modelo y la evaluación con métricas clave como Accuracy y Gini. Además, discutimos cómo el desbalanceo puede afectar los resultados y cómo mitigarlo mediante el uso de class_weight."
      ],
      "metadata": {
        "id": "FGQlfHKsC_m3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Gracias por completar este laboratorio!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0JnheNwzDEFo"
      }
    }
  ]
}